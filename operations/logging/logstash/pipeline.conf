input {
  # Collect logs from Kubernetes pods via Filebeat
  beats {
    port => 5044
    host => "0.0.0.0"
  }
  
  # Collect logs directly from application through TCP
  tcp {
    port => 5000
    codec => json
  }
}

filter {
  # Extract fields from JSON logs
  if [type] == "app" {
    json {
      source => "message"
    }
    
    # Add environment tag
    mutate {
      add_field => { "environment" => "%{[kubernetes][namespace]}" }
    }
    
    # Parse timestamp
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
      remove_field => [ "timestamp" ]
    }
  }
  
  # Process web server logs
  if [type] == "nginx" {
    grok {
      match => { "message" => "%{IPORHOST:remote_ip} - %{DATA:user_name} \[%{HTTPDATE:time}\] \"%{WORD:method} %{DATA:url} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:body_sent_bytes} \"%{DATA:referrer}\" \"%{DATA:agent}\"" }
    }
    
    # Parse timestamp
    date {
      match => [ "time", "dd/MMM/YYYY:HH:mm:ss Z" ]
      target => "@timestamp"
      remove_field => [ "time" ]
    }
    
    # Add response time categories
    if [response_time] {
      ruby {
        code => "
          rt = event.get('response_time').to_f
          if rt < 0.01
            event.set('response_time_category', 'fast')
          elsif rt < 0.1
            event.set('response_time_category', 'medium')
          else
            event.set('response_time_category', 'slow')
          end
        "
      }
    }
    
    # Extract request path without query params
    if [url] {
      grok {
        match => { "url" => "%{DATA:request_path}\?*%{GREEDYDATA:query_string}" }
      }
    }
  }
  
  # Process database logs
  if [type] == "postgres" {
    grok {
      patterns_dir => ["/usr/share/logstash/patterns"]
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} %{GREEDYDATA:query}" }
    }
    
    # Parse timestamp
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
      remove_field => [ "timestamp" ]
    }
    
    # Tag slow queries
    if [message] =~ "duration:" {
      grok {
        match => { "message" => "duration: %{NUMBER:query_time:float}" }
      }
      
      if [query_time] > 1.0 {
        mutate {
          add_tag => [ "slow_query" ]
        }
      }
    }
  }
  
  # Add standard fields
  mutate {
    add_field => { 
      "app" => "patient-advocacy-platform"
    }
  }
}

output {
  # Send all logs to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    index => "patient-advocacy-%{type}-%{+YYYY.MM.dd}"
  }
  
  # Copy critical errors to separate index
  if [log_level] == "ERROR" or [log_level] == "FATAL" or [response_code] =~ /^5\d\d$/ or "slow_query" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      user => "${ELASTIC_USER}"
      password => "${ELASTIC_PASSWORD}"
      index => "patient-advocacy-critical-%{+YYYY.MM.dd}"
    }
  }
  
  # Output to stdout for debugging in development
  if [environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }
}
